# file: backend_api.py
"""æ··åˆRAGç³»ç»Ÿåç«¯API"""
import sys
import os
from pathlib import Path
from contextlib import asynccontextmanager

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent  # /home/zzm/Project_1/kg-hk
rag_method_dir = project_root / "4_RAG_method" / "Mix-RAG-v1" # RAGæ–¹æ³•ç›®å½•

# ç¡®ä¿è·¯å¾„å­˜åœ¨
if str(rag_method_dir) not in sys.path:
    sys.path.insert(0, str(rag_method_dir))

# å¯¼å…¥RAGç³»ç»Ÿæ¨¡å—
try:
    sys.path.insert(0, "/home/zzm/Project_1/kg-hk/4_RAG_method/Mix-RAG-v1")
    from data_types import SystemConfig
    from hybrid_rag_system import HybridRAGSystem
    print("âœ… ä½¿ç”¨ç»å¯¹è·¯å¾„å¯¼å…¥æˆåŠŸ")
except ImportError as e2:
    print(f"âŒ ç»å¯¹è·¯å¾„å¯¼å…¥ä¹Ÿå¤±è´¥: {e2}")
    raise

import time
import hashlib
import threading
from datetime import datetime, timedelta
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
import uvicorn
import json
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
rag_system: Optional[HybridRAGSystem] = None
system_config: Optional[SystemConfig] = None

# æŸ¥è¯¢ç¼“å­˜å’ŒçŠ¶æ€ç®¡ç†
class QueryManager:
    """æŸ¥è¯¢ç®¡ç†å™¨ï¼Œé˜²æ­¢é‡å¤å¤„ç†å’Œæä¾›çŠ¶æ€è·Ÿè¸ª"""
    
    def __init__(self):
        self.cache = {}
        self.lock = threading.Lock()
        self.executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="RAG_Worker")
        self.active_queries = set()  # æ­£åœ¨å¤„ç†çš„æŸ¥è¯¢
        self.max_cache_size = 100
        self.cache_ttl = 300  # 5åˆ†é’Ÿ
    
    def get_query_hash(self, question: str) -> str:
        """è·å–æŸ¥è¯¢çš„å“ˆå¸Œå€¼"""
        return hashlib.md5(question.encode('utf-8')).hexdigest()
    
    def is_query_active(self, query_hash: str) -> bool:
        """æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦æ­£åœ¨å¤„ç†ä¸­"""
        with self.lock:
            return query_hash in self.active_queries
    
    def mark_query_active(self, query_hash: str):
        """æ ‡è®°æŸ¥è¯¢ä¸ºå¤„ç†ä¸­"""
        with self.lock:
            self.active_queries.add(query_hash)
    
    def mark_query_inactive(self, query_hash: str):
        """æ ‡è®°æŸ¥è¯¢ä¸ºå¤„ç†å®Œæˆ"""
        with self.lock:
            if query_hash in self.active_queries:
                self.active_queries.remove(query_hash)
    
    def get_cached_result(self, query_hash: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜çš„æŸ¥è¯¢ç»“æœ"""
        with self.lock:
            if query_hash in self.cache:
                cached_data = self.cache[query_hash]
                # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                if datetime.now() - cached_data['timestamp'] < timedelta(seconds=self.cache_ttl):
                    logger.info(f"ç¼“å­˜å‘½ä¸­: {query_hash[:8]}")
                    return cached_data['result']
                else:
                    # è¿‡æœŸåˆ é™¤
                    del self.cache[query_hash]
            return None
    
    def cache_result(self, query_hash: str, result: Dict):
        """ç¼“å­˜æŸ¥è¯¢ç»“æœ"""
        with self.lock:
            # æ¸…ç†è¿‡æœŸç¼“å­˜
            current_time = datetime.now()
            expired_hashes = []
            for qh, data in self.cache.items():
                if current_time - data['timestamp'] > timedelta(seconds=self.cache_ttl):
                    expired_hashes.append(qh)
            
            for qh in expired_hashes:
                del self.cache[qh]
            
            # å¦‚æœç¼“å­˜æ»¡äº†ï¼Œåˆ é™¤æœ€æ—§çš„
            if len(self.cache) >= self.max_cache_size:
                oldest_hash = next(iter(self.cache))
                del self.cache[oldest_hash]
            
            # å­˜å‚¨æ–°ç»“æœ
            self.cache[query_hash] = {
                'result': result,
                'timestamp': current_time
            }

query_manager = QueryManager()

# æ•°æ®æ¨¡å‹
class QueryRequest(BaseModel):
    """æŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    question: str
    include_context: bool = True
    force_refresh: bool = False  # å¼ºåˆ¶åˆ·æ–°ç¼“å­˜

# ä½¿ç”¨ lifespan ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ›¿ä»£ on_event
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼šå¯åŠ¨å’Œå…³é—­"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    global rag_system, system_config
    try:
        logger.info(f"æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        
        # å°è¯•åŠ è½½é…ç½®
        try:
            system_config = SystemConfig()
            logger.info("âœ… ç³»ç»Ÿé…ç½®åŠ è½½æˆåŠŸ")
            logger.info(f"Neo4j URI: {system_config.neo4j_uri}")
            logger.info(f"å‘é‡æ•°æ®åº“è·¯å¾„: {system_config.vector_db_path}")
            logger.info(f"LLMæ¨¡å‹: {system_config.llm_model}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç³»ç»Ÿé…ç½®å¤±è´¥: {e}")
            logger.warning("å°†ç»§ç»­ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œ")
        
        # å°è¯•åˆå§‹åŒ–RAGç³»ç»Ÿ
        try:
            if system_config:
                rag_system = HybridRAGSystem(system_config)
                logger.info("âœ… æ··åˆRAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œ")
        except Exception as e:
            logger.error(f"âŒ RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            logger.warning("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œï¼Œå®é™…RAGç³»ç»Ÿä¸å¯ç”¨")
        
        logger.info("ğŸš€ æ··åˆRAGç³»ç»ŸAPIæœåŠ¡å¯åŠ¨å®Œæˆ")
        yield  # åº”ç”¨è¿è¡ŒæœŸé—´
        
    except Exception as e:
        logger.error(f"ğŸ”¥ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        yield  # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­è¿è¡Œ
    
    finally:
        # å…³é—­æ—¶æ¸…ç†èµ„æº
        if rag_system:
            try:
                rag_system.close()
                logger.info("âœ… ç³»ç»Ÿèµ„æºå·²æ¸…ç†")
            except Exception as e:
                logger.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")

# åˆ›å»ºFastAPIåº”ç”¨ï¼Œä½¿ç”¨ lifespan
app = FastAPI(
    title="èˆªç©ºèˆªå¤©åˆ¶é€ æ··åˆRAGç³»ç»ŸAPI",
    description="ç»“åˆçŸ¥è¯†å›¾è°±ä¸å‘é‡æ£€ç´¢çš„å¯è§£é‡Šæ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    version="2.0",
    lifespan=lifespan
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def safe_process_query(question: str, timeout: int = 30) -> Dict:
    """å®‰å…¨å¤„ç†æŸ¥è¯¢ï¼Œé¿å…æ— é™å¾ªç¯"""
    import threading
    import queue
    
    result_queue = queue.Queue()
    
    def process():
        try:
            result = rag_system.process_query(question)
            result_queue.put(("success", result))
        except Exception as e:
            result_queue.put(("error", str(e)))
    
    # å¯åŠ¨çº¿ç¨‹å¤„ç†æŸ¥è¯¢
    thread = threading.Thread(target=process)
    thread.daemon = True
    thread.start()
    
    # ç­‰å¾…ç»“æœï¼Œè¶…æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
    try:
        thread.join(timeout=timeout)
        
        if thread.is_alive():
            logger.warning(f"æŸ¥è¯¢å¤„ç†è¶…æ—¶: {question[:50]}...")
            raise TimeoutError(f"æŸ¥è¯¢å¤„ç†è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
        
        status, data = result_queue.get(timeout=1)
        
        if status == "success":
            return data
        else:
            raise Exception(f"å¤„ç†å¤±è´¥: {data}")
            
    except queue.Empty:
        logger.error("ç»“æœé˜Ÿåˆ—ä¸ºç©º")
        raise Exception("å¤„ç†ç»“æœä¸ºç©º")
    except TimeoutError as e:
        raise e
    except Exception as e:
        raise e

def get_mock_response(query: str) -> Dict:
    """è·å–æ¨¡æ‹Ÿå“åº”æ•°æ®"""
    from datetime import datetime
    
    # æ ¹æ®æŸ¥è¯¢å†…å®¹ç”Ÿæˆä¸åŒç±»å‹çš„å“åº”
    if "HB 8766" in query or "8766" in query:
        return {
            "question": query,
            "router_analysis": {
                "type_id": 1,
                "question_type": "simple_fact",
                "entities": ["HB 8766-2025"],
                "intent": "æŸ¥è¯¢æ ‡å‡†å‘å¸ƒä¿¡æ¯",
                "metadata": {"source": "llm_analysis"}
            },
            "retrieval": {
                "kg_results": {
                    "ke_results": [
                        {
                            "source": "HB 8766-2025.md",
                            "paragrepa": [
                                {
                                    "text": "æœ¬æ ‡å‡†äº2025å¹´1æœˆ15æ—¥å‘å¸ƒï¼Œè‡ª2025å¹´7æœˆ1æ—¥èµ·å®æ–½ã€‚æœ¬æ ‡å‡†ç”±èˆªç©ºèˆªå¤©æ ‡å‡†åŒ–å§”å‘˜ä¼šæå‡ºå¹¶å½’å£ã€‚",
                                    "triples": [
                                        {"head": "HB 8766-2025", "relation": "å‘å¸ƒæ—¶é—´", "tail": "2025å¹´1æœˆ15æ—¥", "confidence": 0.95},
                                        {"head": "HB 8766-2025", "relation": "å®æ–½æ—¶é—´", "tail": "2025å¹´7æœˆ1æ—¥", "confidence": 0.95},
                                        {"head": "HB 8766-2025", "relation": "å½’å£å•ä½", "tail": "èˆªç©ºèˆªå¤©æ ‡å‡†åŒ–å§”å‘˜ä¼š", "confidence": 0.95}
                                    ]
                                }
                            ]
                        }
                    ],
                    "entities": ["HB 8766-2025", "èˆªç©ºèˆªå¤©æ ‡å‡†åŒ–å§”å‘˜ä¼š", "2025å¹´1æœˆ15æ—¥", "2025å¹´7æœˆ1æ—¥"],
                    "query_time": 0.12
                },
                "vector_results": [
                    {
                        "chunk_id": "123",
                        "source": "HB 8766-2025.md",
                        "chunk_text": "æœ¬æ ‡å‡†è§„å®šäº†é›·è¾¾ç½©ç”µæ€§èƒ½è¯•éªŒçš„è¦æ±‚ã€è¯•éªŒæ–¹æ³•ã€è¯•éªŒè®¾å¤‡ã€è¯•éªŒç¨‹åºå’Œè¯•éªŒæŠ¥å‘Šç­‰å†…å®¹ã€‚é€‚ç”¨äºå„ç±»é£è¡Œå™¨é›·è¾¾ç½©çš„ç”µæ€§èƒ½è¯•éªŒã€‚",
                        "similarity_score": 0.85,
                        "retrieval_source": "vector",
                        "metadata": {"file_name": "HB 8766-2025.md", "section": "1.èŒƒå›´"}
                    }
                ],
                "reranked_results": [],
                "retrieval_time": 0.35
            },
            "generation": {
                "answer": "HB 8766-2025æ ‡å‡†äº2025å¹´1æœˆ15æ—¥å‘å¸ƒ[1]ï¼Œè‡ª2025å¹´7æœˆ1æ—¥èµ·å®æ–½[1]ã€‚è´Ÿè´£å½’å£ç®¡ç†çš„å•ä½æ˜¯èˆªç©ºèˆªå¤©æ ‡å‡†åŒ–å§”å‘˜ä¼š[1]ã€‚",
                "citations": ["HB 8766-2025.md"],
                "citation_extracted_files": ["HB 8766-2025.md"],
                "generation_time": 2.34,
                "raw_response": "ã€ç­”æ¡ˆã€‘HB 8766-2025æ ‡å‡†äº2025å¹´1æœˆ15æ—¥å‘å¸ƒ[1]ï¼Œè‡ª2025å¹´7æœˆ1æ—¥èµ·å®æ–½[1]ã€‚è´Ÿè´£å½’å£ç®¡ç†çš„å•ä½æ˜¯èˆªç©ºèˆªå¤©æ ‡å‡†åŒ–å§”å‘˜ä¼š[1]ã€‚\nã€è¯æ®ã€‘1. HB 8766-2025.md (æœ¬æ ‡å‡†äº2025å¹´1æœˆ15æ—¥å‘å¸ƒ...)"
            },
            "performance": {
                "total_time": 2.89,
                "retrieval_time": 0.35,
                "generation_time": 2.34
            },
            "timestamp": datetime.now().isoformat(),
            "system_info": {
                "kg_uri": "bolt://192.168.1.104:7687",
                "vector_db": "/home/zzm/Project_1/kg-hk/2_kg_construction/kg_vector_db",
                "llm_model": "/hdd1/checkpoints/Qwen/Qwen3-32B"
            }
        }
    elif "é›·è¾¾ç½©" in query and "å®šä¹‰" in query:
        return {
            "question": query,
            "router_analysis": {
                "type_id": 1,
                "question_type": "simple_fact",
                "entities": ["é›·è¾¾ç½©"],
                "intent": "æŸ¥è¯¢å®šä¹‰",
                "metadata": {"source": "llm_analysis"}
            },
            "retrieval": {
                "kg_results": {
                    "ke_results": [
                        {
                            "source": "èˆªç©ºèˆªå¤©æœ¯è¯­æ ‡å‡†.md",
                            "paragrepa": [
                                {
                                    "text": "é›·è¾¾ç½©æ˜¯å®‰è£…åœ¨é›·è¾¾å¤©çº¿å‰æ–¹çš„ä¿æŠ¤ç½©ï¼Œç”¨äºä¿æŠ¤å¤©çº¿å…å—ç¯å¢ƒå½±å“ï¼ŒåŒæ—¶å…è®¸ç”µç£æ³¢é€šè¿‡ã€‚",
                                    "triples": [
                                        {"head": "é›·è¾¾ç½©", "relation": "å®šä¹‰", "tail": "å®‰è£…åœ¨é›·è¾¾å¤©çº¿å‰æ–¹çš„ä¿æŠ¤ç½©", "confidence": 0.92},
                                        {"head": "é›·è¾¾ç½©", "relation": "åŠŸèƒ½", "tail": "ä¿æŠ¤å¤©çº¿å…å—ç¯å¢ƒå½±å“", "confidence": 0.90},
                                        {"head": "é›·è¾¾ç½©", "relation": "ç‰¹æ€§", "tail": "å…è®¸ç”µç£æ³¢é€šè¿‡", "confidence": 0.95}
                                    ]
                                }
                            ]
                        }
                    ],
                    "entities": ["é›·è¾¾ç½©", "é›·è¾¾å¤©çº¿", "ç”µç£æ³¢"],
                    "query_time": 0.10
                },
                "vector_results": [
                    {
                        "chunk_id": "456",
                        "source": "é›·è¾¾ç½©è®¾è®¡è§„èŒƒ.md",
                        "chunk_text": "é›·è¾¾ç½©ï¼ˆRadomeï¼‰æ˜¯é›·è¾¾ç³»ç»Ÿçš„å…³é”®éƒ¨ä»¶ï¼Œé€šå¸¸ç”±å¤åˆææ–™åˆ¶æˆï¼Œå…·æœ‰è‰¯å¥½çš„é€æ³¢æ€§èƒ½å’Œç»“æ„å¼ºåº¦ã€‚",
                        "similarity_score": 0.82,
                        "retrieval_source": "vector",
                        "metadata": {"file_name": "é›·è¾¾ç½©è®¾è®¡è§„èŒƒ.md", "section": "1.å®šä¹‰"}
                    }
                ],
                "reranked_results": [],
                "retrieval_time": 0.28
            },
            "generation": {
                "answer": "é›·è¾¾ç½©æ˜¯å®‰è£…åœ¨é›·è¾¾å¤©çº¿å‰æ–¹çš„ä¿æŠ¤ç½©[1]ï¼Œç”¨äºä¿æŠ¤å¤©çº¿å…å—ç¯å¢ƒå½±å“[1]ï¼ŒåŒæ—¶å…è®¸ç”µç£æ³¢é€šè¿‡[1]ã€‚å®ƒé€šå¸¸ç”±å¤åˆææ–™åˆ¶æˆï¼Œå…·æœ‰è‰¯å¥½çš„é€æ³¢æ€§èƒ½å’Œç»“æ„å¼ºåº¦[2]ã€‚",
                "citations": ["èˆªç©ºèˆªå¤©æœ¯è¯­æ ‡å‡†.md", "é›·è¾¾ç½©è®¾è®¡è§„èŒƒ.md"],
                "citation_extracted_files": ["èˆªç©ºèˆªå¤©æœ¯è¯­æ ‡å‡†.md", "é›·è¾¾ç½©è®¾è®¡è§„èŒƒ.md"],
                "generation_time": 1.98,
                "raw_response": "ã€ç­”æ¡ˆã€‘é›·è¾¾ç½©æ˜¯å®‰è£…åœ¨é›·è¾¾å¤©çº¿å‰æ–¹çš„ä¿æŠ¤ç½©[1]ï¼Œç”¨äºä¿æŠ¤å¤©çº¿å…å—ç¯å¢ƒå½±å“[1]ï¼ŒåŒæ—¶å…è®¸ç”µç£æ³¢é€šè¿‡[1]ã€‚å®ƒé€šå¸¸ç”±å¤åˆææ–™åˆ¶æˆï¼Œå…·æœ‰è‰¯å¥½çš„é€æ³¢æ€§èƒ½å’Œç»“æ„å¼ºåº¦[2]ã€‚\nã€è¯æ®ã€‘1. èˆªç©ºèˆªå¤©æœ¯è¯­æ ‡å‡†.md (é›·è¾¾ç½©æ˜¯å®‰è£…åœ¨é›·è¾¾å¤©çº¿å‰æ–¹çš„ä¿æŠ¤ç½©...)\n2. é›·è¾¾ç½©è®¾è®¡è§„èŒƒ.md (é›·è¾¾ç½©é€šå¸¸ç”±å¤åˆææ–™åˆ¶æˆ...)"
            },
            "performance": {
                "total_time": 2.36,
                "retrieval_time": 0.28,
                "generation_time": 1.98
            },
            "timestamp": datetime.now().isoformat()
        }
    else:
        # é€šç”¨å“åº”
        return {
            "question": query,
            "router_analysis": {
                "type_id": 1,
                "question_type": "simple_fact",
                "entities": ["èˆªç©ºèˆªå¤©", "æ ‡å‡†"],
                "intent": "æŸ¥è¯¢ä¿¡æ¯",
                "metadata": {"source": "llm_analysis"}
            },
            "retrieval": {
                "kg_results": {
                    "ke_results": [],
                    "entities": [],
                    "query_time": 0.05
                },
                "vector_results": [
                    {
                        "chunk_id": "789",
                        "source": "èˆªç©ºèˆªå¤©æ ‡å‡†æ€»è§ˆ.md",
                        "chunk_text": "èˆªç©ºèˆªå¤©åˆ¶é€ æ¶‰åŠå¤§é‡å›½å®¶æ ‡å‡†ï¼ˆGBï¼‰ã€è¡Œä¸šæ ‡å‡†ï¼ˆHBï¼‰å’Œä¼ä¸šæ ‡å‡†ï¼Œç¡®ä¿äº§å“è´¨é‡å’Œå®‰å…¨ã€‚",
                        "similarity_score": 0.75,
                        "retrieval_source": "vector",
                        "metadata": {"file_name": "èˆªç©ºèˆªå¤©æ ‡å‡†æ€»è§ˆ.md", "section": "1.æ¦‚è¿°"}
                    }
                ],
                "reranked_results": [],
                "retrieval_time": 0.22
            },
            "generation": {
                "answer": "æ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘æ‰¾åˆ°äº†ä¸€äº›ç›¸å…³ä¿¡æ¯ï¼šèˆªç©ºèˆªå¤©åˆ¶é€ æ¶‰åŠå¤§é‡å›½å®¶æ ‡å‡†ï¼ˆGBï¼‰ã€è¡Œä¸šæ ‡å‡†ï¼ˆHBï¼‰å’Œä¼ä¸šæ ‡å‡†ï¼Œè¿™äº›æ ‡å‡†ç¡®ä¿äº†äº§å“è´¨é‡å’Œå®‰å…¨[1]ã€‚å¦‚æœæ‚¨æœ‰å…·ä½“æ ‡å‡†ç¼–å·æˆ–é—®é¢˜ï¼Œè¯·æä¾›æ›´å¤šç»†èŠ‚ã€‚",
                "citations": ["èˆªç©ºèˆªå¤©æ ‡å‡†æ€»è§ˆ.md"],
                "citation_extracted_files": ["èˆªç©ºèˆªå¤©æ ‡å‡†æ€»è§ˆ.md"],
                "generation_time": 1.75,
                "raw_response": "ã€ç­”æ¡ˆã€‘æ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘æ‰¾åˆ°äº†ä¸€äº›ç›¸å…³ä¿¡æ¯ï¼šèˆªç©ºèˆªå¤©åˆ¶é€ æ¶‰åŠå¤§é‡å›½å®¶æ ‡å‡†ï¼ˆGBï¼‰ã€è¡Œä¸šæ ‡å‡†ï¼ˆHBï¼‰å’Œä¼ä¸šæ ‡å‡†ï¼Œè¿™äº›æ ‡å‡†ç¡®ä¿äº†äº§å“è´¨é‡å’Œå®‰å…¨[1]ã€‚å¦‚æœæ‚¨æœ‰å…·ä½“æ ‡å‡†ç¼–å·æˆ–é—®é¢˜ï¼Œè¯·æä¾›æ›´å¤šç»†èŠ‚ã€‚\nã€è¯æ®ã€‘1. èˆªç©ºèˆªå¤©æ ‡å‡†æ€»è§ˆ.md (èˆªç©ºèˆªå¤©åˆ¶é€ æ¶‰åŠå¤§é‡å›½å®¶æ ‡å‡†...)"
            },
            "performance": {
                "total_time": 2.02,
                "retrieval_time": 0.22,
                "generation_time": 1.75
            },
            "timestamp": datetime.now().isoformat()
        }

# APIè·¯ç”±
@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "service": "èˆªç©ºèˆªå¤©åˆ¶é€ æ··åˆRAGç³»ç»Ÿ",
        "version": "2.0",
        "status": "running" if rag_system else "simulation",
        "timestamp": datetime.now().isoformat(),
        "mode": "çœŸå®RAGæ¨¡å¼" if rag_system else "æ¨¡æ‹Ÿæ¨¡å¼"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "rag_system": "active" if rag_system else "simulation",
        "query_manager": {
            "cache_size": len(query_manager.cache),
            "active_queries": len(query_manager.active_queries)
        }
    }

@app.post("/api/query")
async def process_query(request: QueryRequest):
    """å¤„ç†å•ä¸ªæŸ¥è¯¢"""
    start_time = time.time()
    query_hash = query_manager.get_query_hash(request.question)
    
    # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†ç›¸åŒæŸ¥è¯¢
    if query_manager.is_query_active(query_hash):
        logger.warning(f"æŸ¥è¯¢å·²åœ¨å¤„ç†ä¸­: {request.question[:50]}...")
        return JSONResponse(
            status_code=409,
            content={
                "status": "processing",
                "message": "ç›¸åŒçš„æŸ¥è¯¢æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™",
                "query_hash": query_hash,
                "timestamp": datetime.now().isoformat()
            }
        )
    
    # æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
    if not request.force_refresh:
        cached_result = query_manager.get_cached_result(query_hash)
        if cached_result:
            processing_time = time.time() - start_time
            cached_result["processing_time"] = processing_time
            cached_result["cache_hit"] = True
            return cached_result
    
    try:
        # æ ‡è®°æŸ¥è¯¢ä¸ºå¤„ç†ä¸­
        query_manager.mark_query_active(query_hash)
        logger.info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {request.question[:50]}...")
        
        result = None
        
        # å¦‚æœRAGç³»ç»Ÿå·²åˆå§‹åŒ–ä¸”å¯ç”¨ï¼Œä½¿ç”¨çœŸå®å¤„ç†
        if rag_system:
            try:
                # ä½¿ç”¨å®‰å…¨å¤„ç†ï¼Œé¿å…æ— é™å¾ªç¯
                result = safe_process_query(request.question, timeout=30)
                processing_time = time.time() - start_time
                result["processing_time"] = processing_time
                result["cache_hit"] = False
                logger.info(f"çœŸå®æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
                
                # ç¼“å­˜ç»“æœ
                query_manager.cache_result(query_hash, result)
                
            except TimeoutError as e:
                logger.warning(f"çœŸå®å¤„ç†è¶…æ—¶ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
                # è¶…æ—¶åä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                result = get_mock_response(request.question)
                result["warning"] = "çœŸå®å¤„ç†è¶…æ—¶ï¼Œå·²è¿”å›æ¨¡æ‹Ÿæ•°æ®"
                result["processing_time"] = time.time() - start_time
                result["cache_hit"] = False
                
            except Exception as e:
                logger.error(f"çœŸå®å¤„ç†å¤±è´¥: {e}")
                # å¤±è´¥åä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                result = get_mock_response(request.question)
                result["error"] = str(e)
                result["warning"] = "çœŸå®å¤„ç†å¤±è´¥ï¼Œå·²è¿”å›æ¨¡æ‹Ÿæ•°æ®"
                result["processing_time"] = time.time() - start_time
                result["cache_hit"] = False
        else:
            # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            result = get_mock_response(request.question)
            processing_time = time.time() - start_time
            result["processing_time"] = processing_time
            result["mode"] = "simulation"
            result["cache_hit"] = False
            logger.info(f"æ¨¡æ‹ŸæŸ¥è¯¢å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
        
        # æ ‡è®°æŸ¥è¯¢å®Œæˆ
        query_manager.mark_query_inactive(query_hash)
        
        return result if result else {
            "question": request.question,
            "error": "å¤„ç†å¤±è´¥ï¼Œæ— ç»“æœ",
            "timestamp": datetime.now().isoformat()
        }
            
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}", exc_info=True)
        # ç¡®ä¿æ ‡è®°æŸ¥è¯¢ä¸ºå®Œæˆ
        query_manager.mark_query_inactive(query_hash)
        
        # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›åŸºæœ¬æ¨¡æ‹Ÿæ•°æ®
        error_response = {
            "question": request.question,
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
            "generation": {
                "answer": "æŠ±æ­‰ï¼Œå¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯ã€‚è¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç³»ç»ŸçŠ¶æ€ã€‚",
                "citations": [],
                "generation_time": 0.0
            },
            "retrieval": {
                "kg_results": {"ke_results": [], "entities": [], "query_time": 0.0},
                "vector_results": [],
                "retrieval_time": 0.0
            },
            "performance": {
                "total_time": time.time() - start_time,
                "retrieval_time": 0.0,
                "generation_time": 0.0
            }
        }
        return error_response

@app.get("/api/test_connection")
async def test_connection():
    """æµ‹è¯•å„ä¸ªç»„ä»¶è¿æ¥çŠ¶æ€"""
    components = {
        "neo4j": "unknown",
        "vector_db": "unknown",
        "llm": "unknown"
    }
    
    if system_config:
        # æµ‹è¯•Neo4jè¿æ¥
        try:
            from neo4j import GraphDatabase
            driver = GraphDatabase.driver(
                system_config.neo4j_uri,
                auth=(system_config.neo4j_user, system_config.neo4j_password),
                connection_timeout=5
            )
            with driver.session() as session:
                result = session.run("RETURN 1 as test")
                if result.single()["test"] == 1:
                    components["neo4j"] = "connected"
            driver.close()
        except Exception as e:
            components["neo4j"] = f"error: {str(e)[:50]}"
        
        # æµ‹è¯•å‘é‡æ•°æ®åº“
        vector_path = Path(system_config.vector_db_path)
        if vector_path.exists():
            components["vector_db"] = "exists"
        else:
            components["vector_db"] = "not_found"
        
        # æµ‹è¯•LLMæœåŠ¡
        try:
            import requests
            response = requests.get(system_config.llm_service_url, timeout=5)
            if response.status_code < 500:
                components["llm"] = "reachable"
            else:
                components["llm"] = f"error: {response.status_code}"
        except Exception as e:
            components["llm"] = f"error: {str(e)[:50]}"
    
    return {
        "timestamp": datetime.now().isoformat(),
        "rag_system_initialized": rag_system is not None,
        "components": components,
        "mode": "çœŸå®æ¨¡å¼" if rag_system else "æ¨¡æ‹Ÿæ¨¡å¼"
    }

if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡å™¨
    import uvicorn
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8885,
        reload=False,  # å…³é—­reloadé¿å…è­¦å‘Š
        log_level="info"
    )