import json
from pathlib import Path
from neo4j import GraphDatabase
from typing import Dict, List, Any, Optional, Tuple
import hashlib
from datetime import datetime
import os
from collections import defaultdict
import re

# === Neo4j é…ç½® ===
NEO4J_URI = "URL"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "PASSWORD"

class SimplifiedKnowledgeGraph:
    def __init__(self, uri: str, user: str, password: str):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æ„å»ºå™¨"""
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        self.entity_cache = {}  # èŠ‚ç‚¹ç¼“å­˜ï¼šnode_id -> èŠ‚ç‚¹ä¿¡æ¯
        self.processed_files = set()  # å·²å¤„ç†æ–‡ä»¶
        self.new_nodes_this_run = set()  # æœ¬æ¬¡è¿è¡Œæ–°å¢çš„èŠ‚ç‚¹
        self.new_relations_this_run = set()  # æœ¬æ¬¡è¿è¡Œæ–°å¢çš„å…³ç³»
        self.stats = {
            "total_nodes": 0,
            "total_relations": 0,
            "nodes_by_type": defaultdict(int),
            "nodes_by_category": defaultdict(int),
            "nodes_by_subcategory": defaultdict(int),
            "relations_by_type": defaultdict(int)
        }
    
    def sanitize_label(self, label: str) -> str:
        """æ¸…ç†æ ‡ç­¾ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦"""
        # ç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ–‡å’Œä¸‹åˆ’çº¿
        sanitized = re.sub(r'[^\w\u4e00-\u9fff]', '_', label)
        # å¦‚æœä»¥æ•°å­—å¼€å¤´ï¼Œæ·»åŠ å‰ç¼€
        if sanitized and sanitized[0].isdigit():
            sanitized = f"_{sanitized}"
        return sanitized
    
    # ==================== åˆ†ç±»æ˜ å°„ ====================
    def categorize_entity(self, entity_type: str) -> tuple:
        """æ ¹æ®å®ä½“ç±»å‹æ˜ å°„åˆ°å¯¹åº”çš„åˆ†ç±»å’Œå­åˆ†ç±»"""
        category_mapping = {
            # æ ‡å‡†æ–‡æ¡£å±‚
            "Standard": ("æ ‡å‡†æ–‡æ¡£å±‚", "æ ‡å‡†ç¼–å·"),
            "Title": ("æ ‡å‡†æ–‡æ¡£å±‚", "æ ‡å‡†æ ‡é¢˜"),
            "Organization": ("æ ‡å‡†æ–‡æ¡£å±‚", "ç»„ç»‡å…³ç³»"),
            
            # æŠ€æœ¯å·¥è‰ºå±‚ - è®¾è®¡ç±»
            "Component": ("æŠ€æœ¯å·¥è‰ºå±‚", "è®¾è®¡ç±»"),
            "Requirement": ("æŠ€æœ¯å·¥è‰ºå±‚", "è®¾è®¡ç±»"),
            "Parameter": ("æŠ€æœ¯å·¥è‰ºå±‚", "è®¾è®¡ç±»"),
            "Value": ("æŠ€æœ¯å·¥è‰ºå±‚", "è®¾è®¡ç±»"),
            
            # æŠ€æœ¯å·¥è‰ºå±‚ - ææ–™ç±»
            "Material": ("æŠ€æœ¯å·¥è‰ºå±‚", "ææ–™ç±»"),
            
            # æŠ€æœ¯å·¥è‰ºå±‚ - å·¥è‰ºç±»
            "Process": ("æŠ€æœ¯å·¥è‰ºå±‚", "å·¥è‰ºç±»"),
            
            # æŠ€æœ¯å·¥è‰ºå±‚ - è¯•éªŒç±»
            "Test": ("æŠ€æœ¯å·¥è‰ºå±‚", "è¯•éªŒç±»"),
            "Equipment": ("æŠ€æœ¯å·¥è‰ºå±‚", "è¯•éªŒç±»"),

            # æŠ€æœ¯å·¥è‰ºå±‚ - ä¿éšœç±»
            "Defect": ("æŠ€æœ¯å·¥è‰ºå±‚", "ä¿éšœç±»")
        }

        # é»˜è®¤æ˜ å°„åˆ°è®¾è®¡ç±»
        return category_mapping.get(entity_type, ("æŠ€æœ¯å·¥è‰ºå±‚", "è®¾è®¡ç±»"))
    
    # ==================== æ ¸å¿ƒæ„å»ºåŠŸèƒ½ ====================
    def create_hierarchy(self):
        """åˆ›å»ºåˆ†å±‚åˆ†ç±»ä½“ç³»"""
        with self.driver.session() as session:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åˆ†ç±»èŠ‚ç‚¹
            result = session.run("""
                MATCH (c:MainCategory)
                RETURN COUNT(c) as count
            """)
            
            count = result.single()["count"]
            if count > 0:
                print("âœ… åˆ†ç±»ä½“ç³»å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                return
            
            # æ¸…ç©ºç°æœ‰åˆ†ç±»
            session.run("MATCH (c:Category) DETACH DELETE c")
            
            # åˆ›å»ºä¸»åˆ†ç±»å±‚
            main_categories = ["æ ‡å‡†æ–‡æ¡£å±‚", "æŠ€æœ¯å·¥è‰ºå±‚"]
            for main_cat in main_categories:
                session.run("""
                    CREATE (mc:MainCategory {
                        name: $name,
                        level: 'main',
                        created_at: datetime()
                    })
                """, name=main_cat)
            
            # åˆ›å»ºå­åˆ†ç±»å¹¶å…³è”
            sub_categories = {
                "æ ‡å‡†æ–‡æ¡£å±‚": ["æ ‡å‡†ç¼–å·", "æ ‡å‡†æ ‡é¢˜", "ç»„ç»‡å…³ç³»"],
                "æŠ€æœ¯å·¥è‰ºå±‚": ["è®¾è®¡ç±»", "ææ–™ç±»", "å·¥è‰ºç±»", "è¯•éªŒç±»", "ä¿éšœç±»"]
            }
            
            for main_cat, subs in sub_categories.items():
                for sub_cat in subs:
                    session.run("""
                        CREATE (sc:SubCategory {
                            name: $sub_name,
                            level: 'sub',
                            created_at: datetime()
                        })
                        WITH sc
                        MATCH (mc:MainCategory {name: $main_name})
                        CREATE (sc)-[:BELONGS_TO]->(mc)
                    """, sub_name=sub_cat, main_name=main_cat)
            
            print("âœ… åˆ†å±‚åˆ†ç±»ä½“ç³»åˆ›å»ºå®Œæˆ")
    
    def get_node_id(self, entity_name: str, entity_type: str) -> str:
        """ç”ŸæˆèŠ‚ç‚¹å”¯ä¸€IDï¼ˆåŸºäºå°å†™åç§°å’Œç±»å‹ï¼‰"""
        # ä½¿ç”¨å°å†™åç§°å’Œç±»å‹ç»„åˆç”ŸæˆMD5å“ˆå¸Œä½œä¸ºå”¯ä¸€ID
        combined = f"{entity_name.strip().lower()}:{entity_type.strip().lower()}"
        return hashlib.md5(combined.encode()).hexdigest()
    
    def node_exists(self, node_id: str) -> Tuple[bool, Optional[Dict]]:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²å­˜åœ¨ï¼Œè¿”å›æ˜¯å¦å­˜åœ¨å’ŒèŠ‚ç‚¹ä¿¡æ¯"""
        # å…ˆæ£€æŸ¥ç¼“å­˜
        if node_id in self.entity_cache:
            return True, self.entity_cache[node_id]
        
        # å†æ£€æŸ¥æ•°æ®åº“
        with self.driver.session() as session:
            result = session.run("""
                MATCH (n:Entity {node_id: $node_id})
                RETURN n.name as name, n.type as type, 
                       n.category as category, n.subcategory as subcategory
                LIMIT 1
            """, node_id=node_id)
            
            record = result.single()
            if record:
                node_info = {
                    "name": record["name"],
                    "type": record["type"],
                    "category": record.get("category", ""),
                    "subcategory": record.get("subcategory", "")
                }
                self.entity_cache[node_id] = node_info
                return True, node_info
        
        return False, None
    
    def create_node(self, entity: Dict[str, Any]) -> Tuple[Optional[str], bool]:
        """åˆ›å»ºå®ä½“èŠ‚ç‚¹ï¼Œè¿”å›ï¼ˆèŠ‚ç‚¹IDï¼Œæ˜¯å¦æ–°å»ºï¼‰"""
        entity_name = entity.get("name", "").strip()
        entity_type = entity.get("type", "Unknown").strip()
        
        if not entity_name:
            return None, False
        
        # ç”ŸæˆèŠ‚ç‚¹ID
        node_id = self.get_node_id(entity_name, entity_type)
        
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²å­˜åœ¨
        exists, node_info = self.node_exists(node_id)
        if exists:
            return node_id, False  # èŠ‚ç‚¹å·²å­˜åœ¨ï¼Œä¸æ˜¯æ–°å»º
        
        # è·å–åˆ†ç±»
        category, subcategory = self.categorize_entity(entity_type)
        
        # æ¸…ç†æ ‡ç­¾
        clean_entity_type = self.sanitize_label(entity_type)
        
        # åˆ›å»ºèŠ‚ç‚¹
        with self.driver.session() as session:
            try:
                # åˆ›å»ºå®ä½“èŠ‚ç‚¹ï¼Œä½¿ç”¨å®ä½“ç±»å‹ä½œä¸ºæ ‡ç­¾
                query = f"""
                    CREATE (n:Entity:{clean_entity_type} {{
                        name: $name,
                        type: $type,
                        category: $category,
                        subcategory: $subcategory,
                        node_id: $node_id,
                        created_at: datetime()
                    }})
                    RETURN n.node_id as node_id
                """
                
                result = session.run(query, 
                                     name=entity_name, 
                                     type=entity_type,
                                     category=category, 
                                     subcategory=subcategory,
                                     node_id=node_id)
                
                record = result.single()
                if record:
                    actual_node_id = record["node_id"]
                    
                    # æ›´æ–°ç¼“å­˜
                    self.entity_cache[actual_node_id] = {
                        "name": entity_name,
                        "type": entity_type,
                        "category": category,
                        "subcategory": subcategory
                    }
                    
                    # æ·»åŠ åˆ°æœ¬æ¬¡è¿è¡Œçš„æ–°èŠ‚ç‚¹é›†åˆ
                    self.new_nodes_this_run.add(actual_node_id)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.stats["total_nodes"] += 1
                    self.stats["nodes_by_type"][entity_type] += 1
                    self.stats["nodes_by_category"][category] += 1
                    self.stats["nodes_by_subcategory"][subcategory] += 1
                    
                    # å…³è”åˆ°åˆ†ç±»èŠ‚ç‚¹
                    self.link_to_category(actual_node_id, subcategory)
                    
                    return actual_node_id, True
                    
            except Exception as e:
                # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸ºèŠ‚ç‚¹å·²å­˜åœ¨ï¼ˆå¹¶å‘é—®é¢˜ï¼‰
                print(f"âš ï¸  åˆ›å»ºèŠ‚ç‚¹å¤±è´¥: {e}")
                # å†æ¬¡æ£€æŸ¥
                exists, _ = self.node_exists(node_id)
                if exists:
                    return node_id, False
        
        return None, False
    
    def link_to_category(self, node_id: str, subcategory: str):
        """å°†èŠ‚ç‚¹å…³è”åˆ°å­åˆ†ç±»"""
        with self.driver.session() as session:
            try:
                session.run("""
                    MATCH (n:Entity {node_id: $node_id})
                    MATCH (sc:SubCategory {name: $subcategory})
                    MERGE (n)-[:CLASSIFIED_AS]->(sc)
                """, node_id=node_id, subcategory=subcategory)
            except Exception as e:
                print(f"âš ï¸  å…³è”åˆ†ç±»å¤±è´¥: {e}")
    
    def relation_exists(self, head_id: str, tail_id: str, rel_type: str) -> bool:
        """æ£€æŸ¥å…³ç³»æ˜¯å¦å·²å­˜åœ¨"""
        clean_rel_type = self.sanitize_label(rel_type)
        rel_key = f"{head_id}->{tail_id}->{clean_rel_type}"
        
        # æ£€æŸ¥æ˜¯å¦å·²åœ¨æœ¬æ¬¡è¿è¡Œä¸­åˆ›å»º
        if rel_key in self.new_relations_this_run:
            return True
        
        # æ£€æŸ¥æ•°æ®åº“
        with self.driver.session() as session:
            query = f"""
                MATCH (h:Entity {{node_id: $head_id}})-[r:`{clean_rel_type}`]->(t:Entity {{node_id: $tail_id}})
                RETURN COUNT(r) as count
                LIMIT 1
            """
            
            result = session.run(query, head_id=head_id, tail_id=tail_id)
            count = result.single()["count"]
            return count > 0
    
    def create_relation(self, head_id: str, tail_id: str, rel_data: Dict[str, Any]) -> Tuple[bool, bool]:
        """åˆ›å»ºå…³ç³»ï¼Œè¿”å›ï¼ˆæ˜¯å¦æˆåŠŸï¼Œæ˜¯å¦æ–°å»ºï¼‰"""
        if not head_id or not tail_id:
            return False, False
        
        rel_type = rel_data.get("relation", "").strip()
        if not rel_type:
            return False, False
        
        # æ¸…ç†å…³ç³»ç±»å‹
        clean_rel_type = self.sanitize_label(rel_type)
        rel_key = f"{head_id}->{tail_id}->{clean_rel_type}"
        
        # æ£€æŸ¥å…³ç³»æ˜¯å¦å·²å­˜åœ¨
        if self.relation_exists(head_id, tail_id, rel_type):
            return True, False  # å…³ç³»å·²å­˜åœ¨ï¼Œä¸æ˜¯æ–°å»º
        
        try:
            with self.driver.session() as session:
                # ä½¿ç”¨åŠ¨æ€å…³ç³»ç±»å‹
                query = f"""
                    MATCH (h:Entity {{node_id: $head_id}})
                    MATCH (t:Entity {{node_id: $tail_id}})
                    MERGE (h)-[r:`{clean_rel_type}`]->(t)
                    ON CREATE SET r.confidence = $confidence,
                                 r.source = $source,
                                 r.paragraph = $paragraph,
                                 r.created_at = datetime(),
                                 r.relation_type = $rel_type
                    RETURN COUNT(r) as count
                """
                
                result = session.run(query, 
                    head_id=head_id, 
                    tail_id=tail_id,
                    confidence=float(rel_data.get("confidence", 0.5)),
                    source=rel_data.get("source", ""),
                    paragraph=rel_data.get("paragraph", ""),
                    rel_type=rel_type)
                
                if result.single()["count"] > 0:
                    # æ·»åŠ åˆ°æœ¬æ¬¡è¿è¡Œçš„æ–°å…³ç³»é›†åˆ
                    self.new_relations_this_run.add(rel_key)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.stats["total_relations"] += 1
                    self.stats["relations_by_type"][rel_type] += 1
                    
                    return True, True  # å…³ç³»åˆ›å»ºæˆåŠŸï¼Œæ˜¯æ–°å»º
                    
        except Exception as e:
            print(f"âŒ åˆ›å»ºå…³ç³»å¤±è´¥: {e}")
        
        return False, False
    
    # ==================== æ–‡ä»¶å¤„ç† ====================
    def process_json_file(self, file_path: Path) -> Dict[str, int]:
        """å¤„ç†å•ä¸ªJSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {"nodes": 0, "relations": 0}
        
        # ç¡®ä¿æ˜¯åˆ—è¡¨
        if not isinstance(data, list):
            data = [data]
        
        nodes_created = 0
        relations_created = 0
        total_triples = len(data)
        
        print(f"  å¤„ç† {total_triples} ä¸ªä¸‰å…ƒç»„")
        
        for i, item in enumerate(data):
            # åˆ›å»ºèŠ‚ç‚¹ï¼ˆæˆ–è·å–ç°æœ‰èŠ‚ç‚¹ï¼‰
            head_entity = item.get("head", {})
            tail_entity = item.get("tail", {})
            
            head_id, head_is_new = self.create_node(head_entity)
            tail_id, tail_is_new = self.create_node(tail_entity)
            
            # ç»Ÿè®¡æ–°åˆ›å»ºçš„èŠ‚ç‚¹
            if head_is_new:
                nodes_created += 1
            if tail_is_new:
                nodes_created += 1
            
            # åˆ›å»ºå…³ç³»
            if head_id and tail_id:
                rel_created, rel_is_new = self.create_relation(head_id, tail_id, item)
                if rel_created and rel_is_new:
                    relations_created += 1
            
            # æ˜¾ç¤ºè¿›åº¦
            if (i + 1) % 100 == 0 or (i + 1) == total_triples:
                print(f"    è¿›åº¦: {i+1}/{total_triples} (æ–°èŠ‚ç‚¹: {nodes_created}, æ–°å…³ç³»: {relations_created})")
        
        # è®°å½•å·²å¤„ç†æ–‡ä»¶ï¼ˆä½¿ç”¨è§„èŒƒåŒ–çš„è·¯å¾„ï¼‰
        normalized_path = str(file_path.absolute())
        self.processed_files.add(normalized_path)
        
        return {"nodes": nodes_created, "relations": relations_created, "triples": total_triples}
    
    def build_from_dir(self, json_dir: Path, clear_first: bool = False):
        """ä»ç›®å½•æ„å»ºçŸ¥è¯†å›¾è°±"""
        # æŸ¥æ‰¾JSONæ–‡ä»¶
        json_files = list(json_dir.rglob("*.json"))
        if not json_files:
            print(f"âŒ æœªæ‰¾åˆ°JSONæ–‡ä»¶: {json_dir}")
            return
        
        print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªæ–‡ä»¶")
        
        # é‡ç½®æœ¬æ¬¡è¿è¡Œçš„ç»Ÿè®¡
        self.new_nodes_this_run = set()
        self.new_relations_this_run = set()
        
        # æ¸…ç©ºæ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if clear_first:
            self.clear_database()
        else:
            # å¢é‡æ›´æ–°æ—¶ï¼ŒåŠ è½½ç¼“å­˜
            self.load_cache_from_db()
        
        # åˆ›å»ºåˆ†ç±»ä½“ç³»
        self.create_hierarchy()
        
        # å¤„ç†æ–‡ä»¶
        total_stats = {"nodes": 0, "relations": 0, "files_processed": 0}
        
        for json_file in json_files:
            print(f"\nå¤„ç†: {json_file.name}")
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡ï¼ˆè§„èŒƒåŒ–è·¯å¾„ï¼‰
            normalized_path = str(json_file.absolute())
            if normalized_path in self.processed_files:
                print(f"  â­ï¸  æ–‡ä»¶å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
                continue
            
            stats = self.process_json_file(json_file)
            total_stats["nodes"] += stats["nodes"]
            total_stats["relations"] += stats["relations"]
            total_stats["files_processed"] += 1
            print(f"  â†’ æ–°å¢ {stats['nodes']} èŠ‚ç‚¹, {stats['relations']} å…³ç³»")
        
        # ä¿å­˜ç»Ÿè®¡
        self.save_statistics()
        
        print(f"\n{'='*60}")
        print(f"âœ… æ„å»ºå®Œæˆ!")
        print(f"ğŸ“Š æœ¬æ¬¡è¿è¡Œç»Ÿè®¡:")
        print(f"   æ–°å¢èŠ‚ç‚¹: {total_stats['nodes']}")
        print(f"   æ–°å¢å…³ç³»: {total_stats['relations']}")
        print(f"   å¤„ç†æ–‡ä»¶æ•°: {total_stats['files_processed']}")
        print(f"   è·³è¿‡æ–‡ä»¶æ•°: {len(json_files) - total_stats['files_processed']}")
        print(f"\nğŸ“Š ç´¯è®¡ç»Ÿè®¡:")
        print(f"   æ€»èŠ‚ç‚¹æ•°: {self.stats['total_nodes']}")
        print(f"   æ€»å…³ç³»æ•°: {self.stats['total_relations']}")
    
    # ==================== æ•°æ®åº“æ“ä½œ ====================
    def clear_database(self):
        """æ¸…ç©ºæ•°æ®åº“"""
        confirm = input("âš ï¸  æ¸…ç©ºæ•°æ®åº“ï¼Ÿè¾“å…¥ 'YES' ç¡®è®¤: ")
        if confirm != "YES":
            print("æ“ä½œå–æ¶ˆ")
            return
        
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
        
        # é‡ç½®çŠ¶æ€
        self.entity_cache = {}
        self.processed_files = set()
        self.new_nodes_this_run = set()
        self.new_relations_this_run = set()
        self.stats = {
            "total_nodes": 0,
            "total_relations": 0,
            "nodes_by_type": defaultdict(int),
            "nodes_by_category": defaultdict(int),
            "nodes_by_subcategory": defaultdict(int),
            "relations_by_type": defaultdict(int)
        }
        
        print("âœ… æ•°æ®åº“å·²æ¸…ç©º")
    
    def load_cache_from_db(self):
        """ä»æ•°æ®åº“åŠ è½½ç¼“å­˜"""
        with self.driver.session() as session:
            # åŠ è½½èŠ‚ç‚¹
            result = session.run("""
                MATCH (n:Entity)
                RETURN n.node_id as node_id, n.name as name, n.type as type,
                       n.category as category, n.subcategory as subcategory
            """)
            
            node_count = 0
            for record in result:
                node_id = record["node_id"]
                self.entity_cache[node_id] = {
                    "name": record["name"],
                    "type": record["type"],
                    "category": record.get("category", ""),
                    "subcategory": record.get("subcategory", "")
                }
                node_count += 1
            
            # åŠ è½½ç»Ÿè®¡
            node_stats = session.run("""
                MATCH (n:Entity)
                RETURN n.type as type, COUNT(n) as count
            """)
            
            # é‡ç½®ç»Ÿè®¡
            self.stats = {
                "total_nodes": node_count,
                "total_relations": 0,
                "nodes_by_type": defaultdict(int),
                "nodes_by_category": defaultdict(int),
                "nodes_by_subcategory": defaultdict(int),
                "relations_by_type": defaultdict(int)
            }
            
            for record in node_stats:
                entity_type = record["type"]
                count = record["count"]
                self.stats["nodes_by_type"][entity_type] = count
            
            # åŠ è½½å…³ç³»ç»Ÿè®¡
            rel_stats = session.run("""
                MATCH ()-[r]->()
                RETURN type(r) as rel_type, COUNT(r) as count
            """)
            
            total_relations = 0
            for record in rel_stats:
                rel_type = record["rel_type"]
                count = record["count"]
                self.stats["relations_by_type"][rel_type] = count
                total_relations += count
            
            self.stats["total_relations"] = total_relations
            
            print(f"âœ… ä»æ•°æ®åº“åŠ è½½ {node_count} ä¸ªèŠ‚ç‚¹, {total_relations} ä¸ªå…³ç³»åˆ°ç¼“å­˜")
    
    def update_single_file(self, file_path: Path):
        """å¢é‡æ›´æ–°å•ä¸ªæ–‡ä»¶"""
        if not file_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return
        
        # è§„èŒƒåŒ–è·¯å¾„
        normalized_path = str(file_path.absolute())
        
        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
        if normalized_path in self.processed_files:
            print(f"â­ï¸  æ–‡ä»¶å·²å¤„ç†è¿‡: {file_path.name}")
            return
        
        # é‡ç½®æœ¬æ¬¡è¿è¡Œçš„ç»Ÿè®¡
        self.new_nodes_this_run = set()
        self.new_relations_this_run = set()
        
        # åŠ è½½ç¼“å­˜
        self.load_cache_from_db()
        
        print(f"\nğŸ”„ å¢é‡æ›´æ–°: {file_path.name}")
        stats = self.process_json_file(file_path)
        
        # ä¿å­˜ç»Ÿè®¡
        self.save_statistics()
        
        print(f"\nâœ… æ›´æ–°å®Œæˆ:")
        print(f"   æ–°å¢èŠ‚ç‚¹: {stats['nodes']}")
        print(f"   æ–°å¢å…³ç³»: {stats['relations']}")
        print(f"   å¤„ç†ä¸‰å…ƒç»„: {stats['triples']}")
        print(f"   ç´¯è®¡æ€»èŠ‚ç‚¹: {self.stats['total_nodes']}")
        print(f"   ç´¯è®¡æ€»å…³ç³»: {self.stats['total_relations']}")
    
    # ==================== æŸ¥è¯¢ç»Ÿè®¡ ====================
    def query_statistics(self, save_path: Optional[Path] = None):
        """æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)
        
        with self.driver.session() as session:
            # 1. æ€»ä½“ç»Ÿè®¡
            result = session.run("""
                MATCH (n:Entity)
                RETURN 
                    COUNT(n) as total_nodes,
                    COUNT(DISTINCT n.type) as node_types,
                    COUNT(DISTINCT n.category) as categories,
                    COUNT(DISTINCT n.subcategory) as subcategories
            """)
            total = result.single()
            
            print(f"æ€»èŠ‚ç‚¹æ•°: {total['total_nodes']}")
            print(f"èŠ‚ç‚¹ç±»å‹æ•°: {total['node_types']}")
            print(f"ä¸»åˆ†ç±»æ•°: {total['categories']}")
            print(f"å­åˆ†ç±»æ•°: {total['subcategories']}")
            
            # 2. å…³ç³»ç»Ÿè®¡
            result = session.run("""
                MATCH ()-[r]->()
                RETURN 
                    COUNT(r) as total_relations,
                    COUNT(DISTINCT type(r)) as relation_types
            """)
            rels = result.single()
            print(f"æ€»å…³ç³»æ•°: {rels['total_relations']}")
            print(f"å…³ç³»ç±»å‹æ•°: {rels['relation_types']}")
            
            # 3. åˆ†ç±»åˆ†å¸ƒ
            print("\nğŸ“ˆ åˆ†ç±»åˆ†å¸ƒ:")
            result = session.run("""
                MATCH (n:Entity)
                WHERE n.category IS NOT NULL AND n.subcategory IS NOT NULL
                RETURN 
                    n.category as category,
                    n.subcategory as subcategory,
                    COUNT(n) as count
                ORDER BY category, count DESC
            """)
            
            categories = defaultdict(list)
            for record in result:
                category = record["category"]
                subcategory = record["subcategory"]
                count = record["count"]
                categories[category].append((subcategory, count))
            
            for category, subcats in categories.items():
                print(f"\n  {category}:")
                for subcat, count in subcats:
                    print(f"    {subcat}: {count} èŠ‚ç‚¹")
            
            # 4. èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒï¼ˆå‰10ï¼‰
            print("\nğŸ”¤ èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒï¼ˆå‰10ï¼‰:")
            result = session.run("""
                MATCH (n:Entity)
                RETURN n.type as type, COUNT(n) as count
                ORDER BY count DESC
                LIMIT 10
            """)
            
            for record in result:
                print(f"  {record['type']}: {record['count']}")
            
            # 5. å…³ç³»ç±»å‹åˆ†å¸ƒï¼ˆå‰10ï¼‰
            print("\nğŸ”— å…³ç³»ç±»å‹åˆ†å¸ƒï¼ˆå‰10ï¼‰:")
            result = session.run("""
                MATCH ()-[r]->()
                RETURN type(r) as type, COUNT(r) as count
                ORDER BY count DESC
                LIMIT 10
            """)
            
            for record in result:
                print(f"  {record['type']}: {record['count']}")
            
            # 6. èŠ‚ç‚¹æ ‡ç­¾ç»Ÿè®¡ï¼ˆä¿®å¤è¯­æ³•é”™è¯¯ï¼‰
            print("\nğŸ·ï¸  èŠ‚ç‚¹æ ‡ç­¾ç»Ÿè®¡:")
            result = session.run("""
                MATCH (n)
                UNWIND labels(n) as label
                WITH label
                WHERE label <> 'Entity'
                RETURN label, COUNT(*) as count
                ORDER BY count DESC
                LIMIT 10
            """)
            
            for record in result:
                print(f"  {record['label']}: {record['count']}")
            
            # 7. æ–‡ä»¶å¤„ç†ç»Ÿè®¡
            print(f"\nğŸ“„ æ–‡ä»¶å¤„ç†ç»Ÿè®¡:")
            print(f"   å·²å¤„ç†æ–‡ä»¶æ•°: {len(self.processed_files)}")
            
            # ä¿å­˜ç»“æœ
            if save_path:
                self._save_query_results(total, rels, categories, save_path)
    
    def _save_query_results(self, total, rels, categories, save_path: Path):
        """ä¿å­˜æŸ¥è¯¢ç»“æœåˆ°æ–‡ä»¶"""
        results = {
            "query_time": datetime.now().isoformat(),
            "total_nodes": total["total_nodes"],
            "node_types": total["node_types"],
            "categories": total["categories"],
            "subcategories": total["subcategories"],
            "total_relations": rels["total_relations"],
            "relation_types": rels["relation_types"],
            "category_distribution": {
                cat: dict(subcats) for cat, subcats in categories.items()
            },
            "entity_cache_size": len(self.entity_cache),
            "processed_files_count": len(self.processed_files)
        }
        
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    
    # ==================== çŠ¶æ€ç®¡ç† ====================
    def save_statistics(self):
        """ä¿å­˜ç»Ÿè®¡ä¿¡æ¯"""
        cache_dir = Path("/home/zzm/Project_1/kg-hk/2_kg_construction/kg_statistics")
        cache_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜ç»Ÿè®¡
        stats_path = cache_dir / "statistics.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump({
                "total_nodes": self.stats["total_nodes"],
                "total_relations": self.stats["total_relations"],
                "nodes_by_type": dict(self.stats["nodes_by_type"]),
                "nodes_by_category": dict(self.stats["nodes_by_category"]),
                "nodes_by_subcategory": dict(self.stats["nodes_by_subcategory"]),
                "relations_by_type": dict(self.stats["relations_by_type"]),
                "processed_files": list(self.processed_files),
                "cache_size": len(self.entity_cache)
            }, f, ensure_ascii=False, indent=2)
    
    def load_statistics(self):
        """åŠ è½½ç»Ÿè®¡ä¿¡æ¯"""
        stats_path = Path("/home/zzm/Project_1/kg-hk/2_kg_construction/kg_statistics") / "statistics.json"
        if stats_path.exists():
            try:
                with open(stats_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æ¢å¤ç»Ÿè®¡
                self.stats["total_nodes"] = data.get("total_nodes", 0)
                self.stats["total_relations"] = data.get("total_relations", 0)
                
                # æ¢å¤defaultdict
                for key in ["nodes_by_type", "nodes_by_category", "nodes_by_subcategory", "relations_by_type"]:
                    if key in data:
                        self.stats[key] = defaultdict(int, data[key])
                
                # æ¢å¤å·²å¤„ç†æ–‡ä»¶
                self.processed_files = set(data.get("processed_files", []))
                
                print(f"âœ… å·²åŠ è½½ç¼“å­˜çŠ¶æ€: {len(self.processed_files)} ä¸ªå·²å¤„ç†æ–‡ä»¶")
                
            except Exception as e:
                print(f"âš ï¸  åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
    
    def close(self):
        """å…³é—­è¿æ¥"""
        self.save_statistics()
        self.driver.close()
        print("ğŸ”Œ è¿æ¥å·²å…³é—­")


# ==================== ä¸»ç¨‹åº ====================
def main():
    """ä¸»ç¨‹åº"""
    print("=" * 60)
    print("åˆ†å±‚çŸ¥è¯†å›¾è°±ç®¡ç†ç³»ç»Ÿ")
    print("=" * 60)
    
    # é…ç½®è·¯å¾„
    DATA_DIR = Path(r"/home/zzm/Project_1/kg-hk/1_extract_data/kg_data/GB")
    OUTPUT_DIR = Path(r"/home/zzm/Project_1/kg-hk/2_kg_construction/kg_statistics")
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # åˆå§‹åŒ–
    kg = SimplifiedKnowledgeGraph(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)
    
    try:
        # åŠ è½½ç¼“å­˜
        kg.load_statistics()
        
        # ç”¨æˆ·é€‰æ‹©
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. å…¨æ–°æ„å»ºï¼ˆæ¸…ç©ºç°æœ‰æ•°æ®ï¼‰")
        print("2. å¢é‡æ›´æ–°å•ä¸ªæ–‡ä»¶")
        print("3. å¢é‡æ›´æ–°ç›®å½•")
        print("4. æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2/3/4): ").strip()
        
        if choice == "1":
            # å…¨æ–°æ„å»º
            print("\nå…¨æ–°æ„å»ºå›¾è°±...")
            kg.build_from_dir(DATA_DIR, clear_first=True)
            
        elif choice == "2":
            # å¢é‡æ›´æ–°å•ä¸ªæ–‡ä»¶
            file_name = input("è¯·è¾“å…¥æ–‡ä»¶åï¼ˆåŒ…å«è·¯å¾„ï¼‰: ").strip()
            file_path = Path(file_name)
            if not file_path.is_absolute():
                file_path = DATA_DIR / file_name
            
            kg.update_single_file(file_path)
            
        elif choice == "3":
            # å¢é‡æ›´æ–°ç›®å½•
            dir_name = input("è¯·è¾“å…¥æ–‡ä»¶å¤¹åï¼ˆåŒ…å«è·¯å¾„ï¼‰: ").strip()
            dir_path = Path(dir_name)
            if not dir_path.is_absolute():
                dir_path = DATA_DIR / dir_name
            
            kg.build_from_dir(dir_path, clear_first=False)
            
        elif choice == "4":
            # æŸ¥è¯¢ç»Ÿè®¡
            save_path = OUTPUT_DIR / f"statistics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            kg.query_statistics(save_path=save_path)
            
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        kg.close()


if __name__ == "__main__":
    main()